import streamlit as st

# LangChain 1.0.0+ ìƒˆë¡œìš´ Agent API
# create_agent: LangChain 1.0.0+ì—ì„œ ë„ì…ëœ ìƒˆë¡œìš´ ì—ì´ì „íŠ¸ ìƒì„± í•¨ìˆ˜
# ê¸°ì¡´ì˜ create_tool_calling_agent + AgentExecutorë¥¼ ëŒ€ì²´í•¨
from langchain.agents import create_agent

# ëŒ€í™” ê¸°ë¡ ìë™ ìš”ì•½ ë¯¸ë“¤ì›¨ì–´
# ConversationBufferWindowMemoryì˜ ëŒ€ì•ˆìœ¼ë¡œ, í† í° í•œë„ì— ë„ë‹¬í•˜ë©´ ìë™ìœ¼ë¡œ ëŒ€í™” ë‚´ìš©ì„ ìš”ì•½
from langchain.agents.middleware import SummarizationMiddleware

# ë©”ëª¨ë¦¬ ê´€ë¦¬ë¥¼ ìœ„í•œ LangGraph Checkpointer
# LangChain 1.0.0+ì—ì„œëŠ” LangGraph ê¸°ë°˜ì˜ checkpointerë¥¼ í†µí•´ ëŒ€í™” ê¸°ë¡ì„ ê´€ë¦¬
# ê¸°ì¡´ì˜ ConversationBufferWindowMemoryë¥¼ ëŒ€ì²´
from langgraph.checkpoint.memory import InMemorySaver
import uuid

from langchain_openai import ChatOpenAI
from langchain_anthropic import ChatAnthropic
from langchain_google_genai import ChatGoogleGenerativeAI

# ì»¤ìŠ¤í…€ ë„êµ¬ ì„í¬íŠ¸
# @tool ë°ì½”ë ˆì´í„°ë¡œ ì •ì˜ëœ í•¨ìˆ˜ë“¤ì€ LangChain 1.0.0+ì—ì„œë„ ë™ì¼í•˜ê²Œ ì‚¬ìš© ê°€ëŠ¥
from tools.search_ddg import search_ddg
from tools.fetch_page import fetch_page


###### dotenv(.env)ë¥¼ ì‚¬ìš©í•˜ì§€ ì•ŠëŠ” ê²½ìš° ì…ë ¥í•´ì£¼ì„¸ìš” ######
OPENAI_API_KEY = ""                                  # ì—¬ê¸°ì— OpenAI API Keyë¥¼ ì…ë ¥í•˜ì„¸ìš”
ANTHROPIC_API_KEY = ""                               # ì—¬ê¸°ì— Anthropic API Keyë¥¼ ì…ë ¥í•˜ì„¸ìš”
GOOGLE_API_KEY = ""                                  # ì—¬ê¸°ì— Google Generative AI API Keyë¥¼ ì…ë ¥í•˜ì„¸ìš”


###### dotenv(.env) í˜¹ì€ ìƒë‹¨ì— ì •ì˜ëœ ë³€ìˆ˜ë¥¼ í†µí•´ì„œ API_KEYë¥¼ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤. ######
# 1. dotenv(.env)ì—ì„œ ìš°ì„  ë¡œë“œ ì‹œë„
# 2. í™˜ê²½ë³€ìˆ˜ì— ê°’ì´ ì—†ìœ¼ë©´ ìœ„ì— ì •ì˜ëœ ë³€ìˆ˜ê°’ì„ ê°œë³„ì ìœ¼ë¡œ ì ìš©
import os

# dotenvê°€ ì„¤ì¹˜ë˜ì–´ ìˆìœ¼ë©´ .env íŒŒì¼ ë¡œë“œ
try:
    from dotenv import load_dotenv
    load_dotenv()
except ImportError:
    import warnings
    warnings.warn(
        ".env íŒŒì¼ì„ í†µí•œ API Key ë¡œë“œì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. main.py ìƒë‹¨ì— ì…ë ¥ëœ API Keyë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.",
        ImportWarning,
    )

# .envì— ì—†ê±°ë‚˜ ë¹„ì–´ìˆìœ¼ë©´ ìƒë‹¨ì— ì •ì˜ëœ ë³€ìˆ˜ê°’ ì‚¬ìš©
if not os.getenv("OPENAI_API_KEY") and OPENAI_API_KEY:
    os.environ["OPENAI_API_KEY"] = OPENAI_API_KEY

if not os.getenv("ANTHROPIC_API_KEY") and ANTHROPIC_API_KEY:
    os.environ["ANTHROPIC_API_KEY"] = ANTHROPIC_API_KEY

if not os.getenv("GOOGLE_API_KEY") and GOOGLE_API_KEY:
    os.environ["GOOGLE_API_KEY"] = GOOGLE_API_KEY

missing_keys = []
if not os.getenv("OPENAI_API_KEY"):
    missing_keys.append("OPENAI_API_KEY")
if not os.getenv("ANTHROPIC_API_KEY"):
    missing_keys.append("ANTHROPIC_API_KEY")
if not os.getenv("GOOGLE_API_KEY"):
    missing_keys.append("GOOGLE_API_KEY")

if missing_keys:
    import warnings
    warnings.warn(
        f"ë‹¤ìŒ API Keyê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤: {', '.join(missing_keys)}. "
        ".env íŒŒì¼ì„ ì‚¬ìš©í•˜ê±°ë‚˜, main.py ìƒë‹¨ì— ì§ì ‘ API Keyë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.",
        UserWarning,
    )
################################################


# ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ì •ì˜
# LangChain 1.0.0+ì—ì„œëŠ” create_agentì˜ system_prompt íŒŒë¼ë¯¸í„°ë¡œ ì§ì ‘ ì „ë‹¬
# ê¸°ì¡´ì˜ ChatPromptTemplate êµ¬ì„± ì—†ì´ ë¬¸ìì—´ë¡œ ê°„ë‹¨í•˜ê²Œ ì „ë‹¬ ê°€ëŠ¥
CUSTOM_SYSTEM_PROMPT = """
ë‹¹ì‹ ì€ ì‚¬ìš©ìì˜ ìš”ì²­ì— ë”°ë¼ ì¸í„°ë„·ì—ì„œ ì •ë³´ë¥¼ ì¡°ì‚¬í•˜ëŠ” ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.
ì‚¬ìš© ê°€ëŠ¥í•œ ë„êµ¬ë¥¼ í™œìš©í•˜ì—¬ ì¡°ì‚¬í•œ ì •ë³´ë¥¼ ì„¤ëª…í•´ì£¼ì„¸ìš”.
ì´ë¯¸ ì•Œê³  ìˆëŠ” ì •ë³´ë§Œìœ¼ë¡œ ë‹µë³€í•˜ì§€ ë§ê³ , ê°€ëŠ¥í•œ í•œ ê²€ìƒ‰ì„ ìˆ˜í–‰í•œ ë’¤ ë‹µë³€í•´ì£¼ì„¸ìš”.
(ì‚¬ìš©ìê°€ ì½ì„ í˜ì´ì§€ë¥¼ ì§€ì •í•˜ëŠ” ë“± íŠ¹ë³„í•œ ê²½ìš°ëŠ” ê²€ìƒ‰í•˜ì§€ ì•Šì•„ë„ ë©ë‹ˆë‹¤.)

ê²€ìƒ‰ ê²°ê³¼ í˜ì´ì§€ë§Œ í™•ì¸í–ˆì„ ë•Œ ì •ë³´ê°€ ì¶©ë¶„í•˜ì§€ ì•Šë‹¤ê³  íŒë‹¨ë˜ë©´ ë‹¤ìŒ ì˜µì…˜ì„ ê³ ë ¤í•´ ì‹œë„í•´ ì£¼ì„¸ìš”.

- ê²€ìƒ‰ ê²°ê³¼ì˜ ë§í¬ë¥¼ í´ë¦­í•´ ê° í˜ì´ì§€ì˜ ì½˜í…ì¸ ë¥¼ ì—´ëŒí•˜ê³  ë‚´ìš©ì„ í™•ì¸í•˜ì„¸ìš”.
- í•œ í˜ì´ì§€ê°€ ë„ˆë¬´ ê¸¸ ê²½ìš°, 3í˜ì´ì§€ ì´ìƒ ìŠ¤í¬ë¡¤í•˜ì§€ ë§ˆì„¸ìš” (ë©”ëª¨ë¦¬ ë¶€ë‹´ ë•Œë¬¸).
- ê²€ìƒ‰ ì¿¼ë¦¬ë¥¼ ë³€ê²½í•œ ë’¤ ë‹¤ì‹œ ê²€ìƒ‰ì„ ì‹œë„í•˜ì„¸ìš”.
- ê³µì‹ ë¬¸ì„œë¿ ì•„ë‹ˆë¼ ë¸”ë¡œê·¸, ì»¤ë®¤ë‹ˆí‹° ë“± ë¹„ê³µì‹ ìë£Œë„ í•¨ê»˜ ì°¸ê³ í•˜ì„¸ìš”.

ì‚¬ìš©ìëŠ” ë§¤ìš° ë°”ì˜ë©°, ë‹¹ì‹ ë§Œí¼ ì—¬ìœ ë¡­ì§€ ì•ŠìŠµë‹ˆë‹¤.
ë”°ë¼ì„œ ì‚¬ìš©ìì˜ ìˆ˜ê³ ë¥¼ ëœì–´ì£¼ê¸° ìœ„í•´ **ì§ì ‘ì ì¸ ë‹µë³€**ì„ ì œê³µí•´ì£¼ì„¸ìš”.

=== ë‚˜ìœ ë‹µë³€ ì˜ˆì‹œ ===
- ë‹¤ìŒ í˜ì´ì§€ë“¤ì„ ì°¸ê³ í•˜ì„¸ìš”.
- ì´ í˜ì´ì§€ë“¤ì„ ë³´ê³  ì½”ë“œë¥¼ ì‘ì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
- ë‹¤ìŒ í˜ì´ì§€ê°€ ë„ì›€ì´ ë  ê²ƒì…ë‹ˆë‹¤.

=== ì¢‹ì€ ë‹µë³€ ì˜ˆì‹œ ===
- ì´ ë¬¸ì œì˜ í•´ê²° ì˜ˆì‹œëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤. -- ì—¬ê¸° ì½”ë“œ ì œì‹œ --
- ì§ˆë¬¸ì— ëŒ€í•œ ë‹µì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤. -- ì—¬ê¸° ë‹µë³€ ì œì‹œ --

ë‹µë³€ ë§ˆì§€ë§‰ì—ëŠ” **ì°¸ì¡°í•œ í˜ì´ì§€ì˜ URLì„ ë°˜ë“œì‹œ ê¸°ì¬**í•´ì£¼ì„¸ìš”.
(ì‚¬ìš©ìê°€ ì •ë³´ë¥¼ ê²€ì¦í•  ìˆ˜ ìˆë„ë¡)

ì‚¬ìš©ìê°€ ì‚¬ìš©í•˜ëŠ” ì–¸ì–´ë¡œ ë‹µë³€í•´ì£¼ì„¸ìš”.
ì‚¬ìš©ìê°€ í•œêµ­ì–´ë¡œ ì§ˆë¬¸í•˜ë©´ í•œêµ­ì–´ë¡œ, ìŠ¤í˜ì¸ì–´ë¡œ ì§ˆë¬¸í•˜ë©´ ìŠ¤í˜ì¸ì–´ë¡œ ë‹µë³€í•´ì•¼ í•©ë‹ˆë‹¤.
"""


def init_page():
    st.set_page_config(page_title="Web Browsing Agent", page_icon="ğŸ¤—")
    st.header("Web Browsing Agent ğŸ¤—")
    st.sidebar.title("Options")

def init_messages():

    clear_button = st.sidebar.button("Clear Conversation", key="clear")
    if clear_button or "messages" not in st.session_state:
        # ì´ˆê¸° í™˜ì˜ ë©”ì‹œì§€ ì„¤ì •
        st.session_state.messages = [
            {"role": "assistant", "content": "ì•ˆë…•í•˜ì„¸ìš”! ë¬´ì—‡ì´ë“  ì§ˆë¬¸í•´ì£¼ì„¸ìš”!"}
        ]
        # LangGraph Checkpointer ì´ˆê¸°í™”
        # InMemorySaver: ë©”ëª¨ë¦¬ ê¸°ë°˜ ì²´í¬í¬ì¸í„° (ì•± ì¬ì‹œì‘ ì‹œ ì´ˆê¸°í™”ë¨)
        st.session_state["checkpointer"] = InMemorySaver()

        # thread_id: ëŒ€í™” ì„¸ì…˜ì„ êµ¬ë¶„í•˜ëŠ” ê³ ìœ  ì‹ë³„ì
        # ë™ì¼í•œ thread_idë¥¼ ì‚¬ìš©í•˜ë©´ ì´ì „ ëŒ€í™” ë‚´ì—­ì´ ìœ ì§€ë¨
        # ìƒˆ ëŒ€í™”ë¥¼ ì‹œì‘í•  ë•Œë§ˆë‹¤ ìƒˆë¡œìš´ thread_id ìƒì„±
        st.session_state["thread_id"] = str(uuid.uuid4())


def select_model():
    models = ("GPT-5.2", "Claude Sonnet 4.5", "Gemini 2.5 Flash")
    model = st.sidebar.radio("Choose a model:", models)

    # ëª¨ë¸ ì¸ìŠ¤í„´ìŠ¤ ì§ì ‘ ìƒì„± ë°©ì‹ (ì„¸ë¶€ ì„¤ì •ì´ í•„ìš”í•œ ê²½ìš°)
    # temperature=0ìœ¼ë¡œ ì„¤ì •í•˜ì—¬ ì¼ê´€ëœ ì‘ë‹µ ìƒì„±
    if model == "GPT-5.2":
        return ChatOpenAI(temperature=0, model="gpt-5.2")
    elif model == "Claude Sonnet 4.5":
        return ChatAnthropic(temperature=0, model="claude-sonnet-4-5-20250929")
    elif model == "Gemini 2.5 Flash":
        return ChatGoogleGenerativeAI(temperature=0, model="gemini-2.5-flash")


def create_web_browsing_agent():
    tools = [search_ddg, fetch_page]
    llm = select_model()

    # ëŒ€í™” ê¸°ë¡ ìë™ ìš”ì•½ ë¯¸ë“¤ì›¨ì–´ ì„¤ì •
    # ConversationBufferWindowMemory(k=10)ì˜ ëŒ€ì•ˆ
    # í† í° í•œë„ì— ë„ë‹¬í•˜ë©´ ì˜¤ë˜ëœ ë©”ì‹œì§€ë¥¼ ìë™ìœ¼ë¡œ ìš”ì•½í•˜ì—¬ ì»¨í…ìŠ¤íŠ¸ ìœ ì§€
    summarization_middleware = SummarizationMiddleware(
        model=llm,                    # ìš”ì•½ì— ì‚¬ìš©í•  LLM (ì—ì´ì „íŠ¸ì™€ ë™ì¼ ëª¨ë¸ ì‚¬ìš©)
        max_tokens_before_summary=8000,  # ì´ í† í° ìˆ˜ë¥¼ ì´ˆê³¼í•˜ë©´ ìš”ì•½ ì‹œì‘
        messages_to_keep=10,          # ìµœê·¼ Nê°œ ë©”ì‹œì§€ëŠ” ìš”ì•½í•˜ì§€ ì•Šê³  ìœ ì§€ (k=10ê³¼ ìœ ì‚¬)
    )

    # LangChain 1.0.0+ create_agent ì‚¬ìš©
    agent = create_agent(
        model=llm,                              # LLM ëª¨ë¸ (ì¸ìŠ¤í„´ìŠ¤ ë˜ëŠ” ë¬¸ìì—´)
        tools=tools,                            # ì‚¬ìš© ê°€ëŠ¥í•œ ë„êµ¬ ë¦¬ìŠ¤íŠ¸
        system_prompt=CUSTOM_SYSTEM_PROMPT,     # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸
        checkpointer=st.session_state["checkpointer"],  # ëŒ€í™” ìƒíƒœ ì €ì¥ìš© ì²´í¬í¬ì¸í„°
        middleware=[summarization_middleware],  # ëŒ€í™” ìš”ì•½ ë¯¸ë“¤ì›¨ì–´ ì ìš©
        debug=True                              # ë””ë²„ê·¸ ëª¨ë“œ (verbose ëŒ€ì²´)
    )

    return agent


def main():
    init_page()
    init_messages()
    web_browsing_agent = create_web_browsing_agent()

    # ê¸°ì¡´ ë©”ì‹œì§€ í‘œì‹œ
    # LangChain 1.0.0+ì—ì„œëŠ” st.session_state.messagesë¥¼ ì§ì ‘ ê´€ë¦¬
    for msg in st.session_state.messages:
        st.chat_message(msg["role"]).write(msg["content"])

    # ì‚¬ìš©ì ì…ë ¥ ì²˜ë¦¬
    if prompt := st.chat_input(placeholder="2025 í•œêµ­ì‹œë¦¬ì¦ˆ ìš°ìŠ¹íŒ€?"):
        # ì‚¬ìš©ì ë©”ì‹œì§€ í‘œì‹œ ë° ì €ì¥
        st.chat_message("user").write(prompt)
        st.session_state.messages.append({"role": "user", "content": prompt})

        with st.chat_message("assistant"):
            # ì—ì´ì „íŠ¸ ì„¤ì •
            config = {"configurable": {"thread_id": st.session_state["thread_id"]}}

            # ìµœì¢… ì‘ë‹µ ì €ì¥
            final_response = ""

            # ì¤‘ê°„ ë‹¨ê³„ í‘œì‹œìš© status
            status_container = st.status("ğŸ¤” Thinking...", expanded=True)

            # ìµœì¢… ì‘ë‹µ ìŠ¤íŠ¸ë¦¬ë°ìš© placeholder
            response_placeholder = st.empty()

            # stream_mode=["messages", "updates"] ì‚¬ìš©
            # - messages: LLM í† í° ìŠ¤íŠ¸ë¦¬ë° (AI ì‘ë‹µ ì‹¤ì‹œê°„ í‘œì‹œ)
            # - updates: ìƒíƒœ ì—…ë°ì´íŠ¸ (ë„êµ¬ í˜¸ì¶œ ì •ë³´, ì‹¤í–‰ ê²°ê³¼ ë“±)
            for stream_mode, data in web_browsing_agent.stream(
                {"messages": [{"role": "user", "content": prompt}]},
                config=config,
                stream_mode=["messages", "updates"]
            ):
                # ========== updates ëª¨ë“œ: ë„êµ¬ í˜¸ì¶œ ë° ì‹¤í–‰ ê²°ê³¼ ì²˜ë¦¬ ==========
                if stream_mode == "updates":
                    for source, update in data.items():
                        # updateê°€ Noneì´ê±°ë‚˜ dictê°€ ì•„ë‹Œ ê²½ìš° ìŠ¤í‚µ
                        if not isinstance(update, dict):
                            continue

                        messages = update.get("messages", [])
                        for msg in messages:
                            # ë„êµ¬ í˜¸ì¶œ ì •ë³´ í‘œì‹œ (model ë…¸ë“œì—ì„œ AIMessageì— tool_callsê°€ ìˆëŠ” ê²½ìš°)
                            if hasattr(msg, 'tool_calls') and msg.tool_calls:
                                for tc in msg.tool_calls:
                                    with status_container:
                                        st.write(f"ğŸ”§ **{tc.get('name', 'tool')}**: `{tc.get('args', {})}`")

                            # ë„êµ¬ ì‹¤í–‰ ê²°ê³¼ í‘œì‹œ (tools ë…¸ë“œì—ì„œ ToolMessage)
                            if source == "tools" and hasattr(msg, 'name'):
                                tool_name = msg.name
                                tool_content = str(msg.content) if hasattr(msg, 'content') else ""

                                with status_container:
                                    st.write(f"âœ… **{tool_name}** ì™„ë£Œ")
                                    # ê²°ê³¼ ë‚´ìš©ì„ expanderë¡œ í‘œì‹œ
                                    with st.expander(f"ğŸ“‹ {tool_name} ê²°ê³¼ ë³´ê¸°", expanded=False):
                                        # ê²°ê³¼ê°€ ë„ˆë¬´ ê¸¸ë©´ ì˜ë¼ì„œ í‘œì‹œ
                                        if len(tool_content) > 2000:
                                            st.code(tool_content[:2000] + "\n... (truncated)", language="text")
                                        else:
                                            st.code(tool_content, language="text")

                # ========== messages ëª¨ë“œ: AI ì‘ë‹µ í† í° ìŠ¤íŠ¸ë¦¬ë° ==========
                elif stream_mode == "messages":
                    chunk, metadata = data

                    # ë„êµ¬ ë…¸ë“œì—ì„œ ì˜¤ëŠ” ë©”ì‹œì§€ëŠ” updatesì—ì„œ ì²˜ë¦¬í–ˆìœ¼ë¯€ë¡œ ìŠ¤í‚µ
                    if metadata.get("langgraph_node") == "tools":
                        continue

                    # AI ì‘ë‹µ í† í° ìŠ¤íŠ¸ë¦¬ë° (tool_call_chunksê°€ ì—†ëŠ” ê²½ìš°ë§Œ)
                    if hasattr(chunk, 'content') and chunk.content:
                        if hasattr(chunk, 'tool_call_chunks') and chunk.tool_call_chunks:
                            continue
                        final_response += chunk.content
                        response_placeholder.markdown(final_response + "â–Œ")

            # status ì™„ë£Œ ì²˜ë¦¬
            status_container.update(label="âœ… Complete!", state="complete", expanded=False)

            # ìµœì¢… ì‘ë‹µ í‘œì‹œ (ì»¤ì„œ ì œê±°)
            if final_response:
                response_placeholder.markdown(final_response)
                st.session_state.messages.append({"role": "assistant", "content": final_response})


if __name__ == "__main__":
    main()
