import streamlit as st
from langchain.agents import create_agent
from langchain.agents.middleware import SummarizationMiddleware
from langgraph.checkpoint.memory import InMemorySaver
import uuid

from langchain_openai import ChatOpenAI
from langchain_anthropic import ChatAnthropic
from langchain_google_genai import ChatGoogleGenerativeAI

from tools.search_ddg import search_ddg
from tools.fetch_page import fetch_page


OPENAI_API_KEY = ""
ANTHROPIC_API_KEY = ""
GOOGLE_API_KEY = ""


import os

try:
    from dotenv import load_dotenv
    load_dotenv()
except ImportError:
    import warnings
    warnings.warn(
        ".env íŒŒì¼ì„ í†µí•œ API Key ë¡œë“œì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. main.py ìƒë‹¨ì— ìž…ë ¥ëœ API Keyë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.",
        ImportWarning,
    )

if not os.getenv("OPENAI_API_KEY") and OPENAI_API_KEY:
    os.environ["OPENAI_API_KEY"] = OPENAI_API_KEY

if not os.getenv("ANTHROPIC_API_KEY") and ANTHROPIC_API_KEY:
    os.environ["ANTHROPIC_API_KEY"] = ANTHROPIC_API_KEY

if not os.getenv("GOOGLE_API_KEY") and GOOGLE_API_KEY:
    os.environ["GOOGLE_API_KEY"] = GOOGLE_API_KEY

missing_keys = []
if not os.getenv("OPENAI_API_KEY"):
    missing_keys.append("OPENAI_API_KEY")
if not os.getenv("ANTHROPIC_API_KEY"):
    missing_keys.append("ANTHROPIC_API_KEY")
if not os.getenv("GOOGLE_API_KEY"):
    missing_keys.append("GOOGLE_API_KEY")

if missing_keys:
    import warnings
    warnings.warn(
        f"ë‹¤ìŒ API Keyê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤: {', '.join(missing_keys)}. "
        ".env íŒŒì¼ì„ ì‚¬ìš©í•˜ê±°ë‚˜, main.py ìƒë‹¨ì— ì§ì ‘ API Keyë¥¼ ìž…ë ¥í•´ì£¼ì„¸ìš”.",
        UserWarning,
    )


CUSTOM_SYSTEM_PROMPT = """
ë‹¹ì‹ ì€ ì‚¬ìš©ìžì˜ ìš”ì²­ì— ë”°ë¼ ì¸í„°ë„·ì—ì„œ ì •ë³´ë¥¼ ì¡°ì‚¬í•˜ëŠ” ì–´ì‹œìŠ¤í„´íŠ¸ìž…ë‹ˆë‹¤.
ì‚¬ìš© ê°€ëŠ¥í•œ ë„êµ¬ë¥¼ í™œìš©í•˜ì—¬ ì¡°ì‚¬í•œ ì •ë³´ë¥¼ ì„¤ëª…í•´ì£¼ì„¸ìš”.
ì´ë¯¸ ì•Œê³  ìžˆëŠ” ì •ë³´ë§Œìœ¼ë¡œ ë‹µë³€í•˜ì§€ ë§ê³ , ê°€ëŠ¥í•œ í•œ ê²€ìƒ‰ì„ ìˆ˜í–‰í•œ ë’¤ ë‹µë³€í•´ì£¼ì„¸ìš”.
(ì‚¬ìš©ìžê°€ ì½ì„ íŽ˜ì´ì§€ë¥¼ ì§€ì •í•˜ëŠ” ë“± íŠ¹ë³„í•œ ê²½ìš°ëŠ” ê²€ìƒ‰í•˜ì§€ ì•Šì•„ë„ ë©ë‹ˆë‹¤.)

ê²€ìƒ‰ ê²°ê³¼ íŽ˜ì´ì§€ë§Œ í™•ì¸í–ˆì„ ë•Œ ì •ë³´ê°€ ì¶©ë¶„í•˜ì§€ ì•Šë‹¤ê³  íŒë‹¨ë˜ë©´ ë‹¤ìŒ ì˜µì…˜ì„ ê³ ë ¤í•´ ì‹œë„í•´ ì£¼ì„¸ìš”.

- ê²€ìƒ‰ ê²°ê³¼ì˜ ë§í¬ë¥¼ í´ë¦­í•´ ê° íŽ˜ì´ì§€ì˜ ì½˜í…ì¸ ë¥¼ ì—´ëžŒí•˜ê³  ë‚´ìš©ì„ í™•ì¸í•˜ì„¸ìš”.
- í•œ íŽ˜ì´ì§€ê°€ ë„ˆë¬´ ê¸¸ ê²½ìš°, 3íŽ˜ì´ì§€ ì´ìƒ ìŠ¤í¬ë¡¤í•˜ì§€ ë§ˆì„¸ìš” (ë©”ëª¨ë¦¬ ë¶€ë‹´ ë•Œë¬¸).
- ê²€ìƒ‰ ì¿¼ë¦¬ë¥¼ ë³€ê²½í•œ ë’¤ ë‹¤ì‹œ ê²€ìƒ‰ì„ ì‹œë„í•˜ì„¸ìš”.
- ê³µì‹ ë¬¸ì„œë¿ ì•„ë‹ˆë¼ ë¸”ë¡œê·¸, ì»¤ë®¤ë‹ˆí‹° ë“± ë¹„ê³µì‹ ìžë£Œë„ í•¨ê»˜ ì°¸ê³ í•˜ì„¸ìš”.

ì‚¬ìš©ìžëŠ” ë§¤ìš° ë°”ì˜ë©°, ë‹¹ì‹ ë§Œí¼ ì—¬ìœ ë¡­ì§€ ì•ŠìŠµë‹ˆë‹¤.
ë”°ë¼ì„œ ì‚¬ìš©ìžì˜ ìˆ˜ê³ ë¥¼ ëœì–´ì£¼ê¸° ìœ„í•´ **ì§ì ‘ì ì¸ ë‹µë³€**ì„ ì œê³µí•´ì£¼ì„¸ìš”.

=== ë‚˜ìœ ë‹µë³€ ì˜ˆì‹œ ===
- ë‹¤ìŒ íŽ˜ì´ì§€ë“¤ì„ ì°¸ê³ í•˜ì„¸ìš”.
- ì´ íŽ˜ì´ì§€ë“¤ì„ ë³´ê³  ì½”ë“œë¥¼ ìž‘ì„±í•  ìˆ˜ ìžˆìŠµë‹ˆë‹¤.
- ë‹¤ìŒ íŽ˜ì´ì§€ê°€ ë„ì›€ì´ ë  ê²ƒìž…ë‹ˆë‹¤.

=== ì¢‹ì€ ë‹µë³€ ì˜ˆì‹œ ===
- ì´ ë¬¸ì œì˜ í•´ê²° ì˜ˆì‹œëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤. -- ì—¬ê¸° ì½”ë“œ ì œì‹œ --
- ì§ˆë¬¸ì— ëŒ€í•œ ë‹µì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤. -- ì—¬ê¸° ë‹µë³€ ì œì‹œ --

ë‹µë³€ ë§ˆì§€ë§‰ì—ëŠ” **ì°¸ì¡°í•œ íŽ˜ì´ì§€ì˜ URLì„ ë°˜ë“œì‹œ ê¸°ìž¬**í•´ì£¼ì„¸ìš”.
(ì‚¬ìš©ìžê°€ ì •ë³´ë¥¼ ê²€ì¦í•  ìˆ˜ ìžˆë„ë¡)

ì‚¬ìš©ìžê°€ ì‚¬ìš©í•˜ëŠ” ì–¸ì–´ë¡œ ë‹µë³€í•´ì£¼ì„¸ìš”.
ì‚¬ìš©ìžê°€ í•œêµ­ì–´ë¡œ ì§ˆë¬¸í•˜ë©´ í•œêµ­ì–´ë¡œ, ìŠ¤íŽ˜ì¸ì–´ë¡œ ì§ˆë¬¸í•˜ë©´ ìŠ¤íŽ˜ì¸ì–´ë¡œ ë‹µë³€í•´ì•¼ í•©ë‹ˆë‹¤.
"""


def init_page():
    st.set_page_config(page_title="Web Browsing Agent", page_icon="ðŸ¤—")
    st.header("Web Browsing Agent ðŸ¤—")
    st.sidebar.title("Options")


def init_messages():
    clear_button = st.sidebar.button("Clear Conversation", key="clear")
    if clear_button or "messages" not in st.session_state:
        st.session_state.messages = [
            {"role": "assistant", "content": "ì•ˆë…•í•˜ì„¸ìš”! ë¬´ì—‡ì´ë“  ì§ˆë¬¸í•´ì£¼ì„¸ìš”!"}
        ]
        st.session_state["checkpointer"] = InMemorySaver()
        st.session_state["thread_id"] = str(uuid.uuid4())


def select_model():
    models = ("GPT-5.2", "Claude Sonnet 4.5", "Gemini 2.5 Flash")
    model = st.sidebar.radio("Choose a model:", models)

    if model == "GPT-5.2":
        return ChatOpenAI(temperature=0, model="gpt-5.2")
    elif model == "Claude Sonnet 4.5":
        return ChatAnthropic(temperature=0, model="claude-sonnet-4-5-20250929")
    elif model == "Gemini 2.5 Flash":
        return ChatGoogleGenerativeAI(temperature=0, model="gemini-2.5-flash")


def create_web_browsing_agent():
    tools = [search_ddg, fetch_page]
    llm = select_model()

    summarization_middleware = SummarizationMiddleware(
        model=llm,
        max_tokens_before_summary=8000,
        messages_to_keep=10,
    )

    agent = create_agent(
        model=llm,
        tools=tools,
        system_prompt=CUSTOM_SYSTEM_PROMPT,
        checkpointer=st.session_state["checkpointer"],
        middleware=[summarization_middleware],
        debug=True
    )

    return agent


def main():
    init_page()
    init_messages()
    web_browsing_agent = create_web_browsing_agent()

    for msg in st.session_state.messages:
        st.chat_message(msg["role"]).write(msg["content"])

    if prompt := st.chat_input(placeholder="2025 í•œêµ­ì‹œë¦¬ì¦ˆ ìš°ìŠ¹íŒ€?"):
        st.chat_message("user").write(prompt)
        st.session_state.messages.append({"role": "user", "content": prompt})

        with st.chat_message("assistant"):
            config = {"configurable": {"thread_id": st.session_state["thread_id"]}}
            final_response = ""
            status_container = st.status("ðŸ¤” Thinking...", expanded=True)
            response_placeholder = st.empty()

            for stream_mode, data in web_browsing_agent.stream(
                {"messages": [{"role": "user", "content": prompt}]},
                config=config,
                stream_mode=["messages", "updates"]
            ):
                if stream_mode == "updates":
                    for source, update in data.items():
                        if not isinstance(update, dict):
                            continue

                        messages = update.get("messages", [])
                        for msg in messages:
                            if hasattr(msg, 'tool_calls') and msg.tool_calls:
                                for tc in msg.tool_calls:
                                    with status_container:
                                        st.write(f"ðŸ”§ **{tc.get('name', 'tool')}**: `{tc.get('args', {})}`")

                            if source == "tools" and hasattr(msg, 'name'):
                                tool_name = msg.name
                                tool_content = str(msg.content) if hasattr(msg, 'content') else ""

                                with status_container:
                                    st.write(f"âœ… **{tool_name}** ì™„ë£Œ")
                                    with st.expander(f"ðŸ“‹ {tool_name} ê²°ê³¼ ë³´ê¸°", expanded=False):
                                        if len(tool_content) > 2000:
                                            st.code(tool_content[:2000] + "\n... (truncated)", language="text")
                                        else:
                                            st.code(tool_content, language="text")

                elif stream_mode == "messages":
                    chunk, metadata = data

                    if metadata.get("langgraph_node") == "tools":
                        continue

                    if hasattr(chunk, 'content') and chunk.content:
                        if hasattr(chunk, 'tool_call_chunks') and chunk.tool_call_chunks:
                            continue
                        final_response += chunk.content
                        response_placeholder.markdown(final_response + "â–Œ")

            status_container.update(label="âœ… Complete!", state="complete", expanded=False)

            if final_response:
                response_placeholder.markdown(final_response)
                st.session_state.messages.append({"role": "assistant", "content": final_response})


if __name__ == "__main__":
    main()
